{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blockchain Fraud Detection: Data Exploration\n",
    "\n",
    "This notebook explores the Elliptic dataset, which contains Bitcoin transactions labeled as licit or illicit. We'll analyze the data structure, feature distributions, and network characteristics.\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "The Elliptic dataset consists of:\n",
    "- **nodes.csv**: Bitcoin transactions with features and labels\n",
    "- **edges.csv**: Transaction flows connecting the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "\n",
    "# Set plotting style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "nodes_path = '../data/raw/nodes.csv'\n",
    "edges_path = '../data/raw/edges.csv'\n",
    "\n",
    "df_nodes = pd.read_csv(nodes_path)\n",
    "df_edges = pd.read_csv(edges_path)\n",
    "\n",
    "print(f\"Node data shape: {df_nodes.shape}\")\n",
    "print(f\"Edge data shape: {df_edges.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine node data\n",
    "print(\"Node data sample:\")\n",
    "df_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine edge data\n",
    "print(\"Edge data sample:\")\n",
    "df_edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in node data:\")\n",
    "print(df_nodes.isnull().sum().sum())\n",
    "\n",
    "print(\"\\nMissing values in edge data:\")\n",
    "print(df_edges.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze Target Distribution (Licit vs. Illicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get target distribution\n",
    "target_counts = df_nodes['class'].value_counts()\n",
    "print(\"Target distribution:\")\n",
    "print(target_counts)\n",
    "print(f\"Fraud percentage: {target_counts[1] / len(df_nodes) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(x='class', data=df_nodes, palette=['#4285F4', '#EA4335'])\n",
    "plt.title('Transaction Class Distribution', fontsize=15)\n",
    "plt.xlabel('Class (0=Legitimate, 1=Fraudulent)', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "# Add count labels\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height():,}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pie chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(target_counts, labels=['Legitimate', 'Fraudulent'], \n",
    "        autopct='%1.2f%%', startangle=90, colors=['#4285F4', '#EA4335'],\n",
    "        wedgeprops={'edgecolor': 'w', 'linewidth': 1.5}, explode=[0.02, 0.05])\n",
    "plt.title('Transaction Class Distribution', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore Time Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there's a time step column\n",
    "if 'time_step' in df_nodes.columns:\n",
    "    # Analyze transactions per time step\n",
    "    time_step_counts = df_nodes['time_step'].value_counts().sort_index()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    time_step_counts.plot(kind='bar', color='skyblue')\n",
    "    plt.title('Transactions per Time Step', fontsize=15)\n",
    "    plt.xlabel('Time Step', fontsize=12)\n",
    "    plt.ylabel('Number of Transactions', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze fraud distribution over time\n",
    "    fraud_by_time = df_nodes.groupby('time_step')['class'].mean()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    fraud_by_time.plot(kind='line', marker='o', color='crimson')\n",
    "    plt.title('Fraud Percentage Over Time', fontsize=15)\n",
    "    plt.xlabel('Time Step', fontsize=12)\n",
    "    plt.ylabel('Percentage of Fraudulent Transactions', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No 'time_step' column found in the data\")\n",
    "    # Try to identify if another column might represent time\n",
    "    for col in df_nodes.columns[2:10]:  # Check first few columns\n",
    "        unique_vals = df_nodes[col].nunique()\n",
    "        if 30 < unique_vals < 100:  # Potential time step column\n",
    "            print(f\"Column {col} has {unique_vals} unique values and might represent time steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics of features\n",
    "feature_stats = df_nodes.iloc[:, 2:].describe().T\n",
    "feature_stats['variance'] = df_nodes.iloc[:, 2:].var()\n",
    "feature_stats = feature_stats.sort_values('variance', ascending=False)\n",
    "\n",
    "print(\"Top 10 features by variance:\")\n",
    "feature_stats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find low-variance features\n",
    "low_var_threshold = 0.01\n",
    "low_var_features = feature_stats[feature_stats['variance'] < low_var_threshold].index.tolist()\n",
    "\n",
    "print(f\"Number of low-variance features (variance < {low_var_threshold}): {len(low_var_features)}\")\n",
    "print(\"Examples of low-variance features:\")\n",
    "feature_stats.loc[low_var_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target\n",
    "feature_correlation = df_nodes.iloc[:, 2:].corrwith(df_nodes['class']).abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 15 features by correlation with fraud label:\")\n",
    "feature_correlation.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top feature correlations\n",
    "plt.figure(figsize=(12, 6))\n",
    "feature_correlation.head(15).plot(kind='bar', color='teal')\n",
    "plt.title('Top 15 Features by Correlation with Fraud Label', fontsize=15)\n",
    "plt.xlabel('Feature', fontsize=12)\n",
    "plt.ylabel('Absolute Correlation', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA to visualize feature space\n",
    "features = df_nodes.iloc[:, 2:].values\n",
    "labels = df_nodes['class'].values\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "features_pca = pca.fit_transform(features)\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "df_pca = pd.DataFrame({\n",
    "    'PC1': features_pca[:, 0],\n",
    "    'PC2': features_pca[:, 1],\n",
    "    'class': labels\n",
    "})\n",
    "\n",
    "# Visualize PCA projection\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=df_pca, x='PC1', y='PC2', hue='class', palette=['#4285F4', '#EA4335'], \n",
    "                alpha=0.6, s=50)\n",
    "plt.title('PCA Projection of Transaction Features', fontsize=15)\n",
    "plt.xlabel(f'Principal Component 1 ({pca.explained_variance_ratio_[0]*100:.2f}%)', fontsize=12)\n",
    "plt.ylabel(f'Principal Component 2 ({pca.explained_variance_ratio_[1]*100:.2f}%)', fontsize=12)\n",
    "plt.legend(title='Class', labels=['Legitimate', 'Fraudulent'])\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Graph Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph from edges\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add edges\n",
    "for _, row in df_edges.iterrows():\n",
    "    G.add_edge(row[0], row[1])\n",
    "\n",
    "print(f\"Graph statistics:\")\n",
    "print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "print(f\"Is directed: {nx.is_directed(G)}\")\n",
    "print(f\"Is connected: {nx.is_weakly_connected(G)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create node mapping for faster lookups\n",
    "node_id_to_class = {row[0]: row[1] for _, row in df_nodes.iterrows()}\n",
    "\n",
    "# Analyze node degrees\n",
    "in_degrees = dict(G.in_degree())\n",
    "out_degrees = dict(G.out_degree())\n",
    "total_degrees = dict(G.degree())\n",
    "\n",
    "# Create a DataFrame for analysis\n",
    "df_degrees = pd.DataFrame({\n",
    "    'node_id': list(G.nodes()),\n",
    "    'in_degree': [in_degrees.get(n, 0) for n in G.nodes()],\n",
    "    'out_degree': [out_degrees.get(n, 0) for n in G.nodes()],\n",
    "    'total_degree': [total_degrees.get(n, 0) for n in G.nodes()],\n",
    "})\n",
    "\n",
    "# Add class information where available\n",
    "df_degrees['class'] = df_degrees['node_id'].map(lambda x: node_id_to_class.get(x, -1))\n",
    "df_degrees = df_degrees[df_degrees['class'] != -1]  # Keep only nodes with class information\n",
    "\n",
    "print(\"Degree statistics:\")\n",
    "print(df_degrees[['in_degree', 'out_degree', 'total_degree']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare degrees by class\n",
    "df_degrees_by_class = df_degrees.groupby('class')[['in_degree', 'out_degree', 'total_degree']].mean()\n",
    "print(\"Average degrees by class:\")\n",
    "print(df_degrees_by_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize degree distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# In-degree distribution\n",
    "sns.histplot(data=df_degrees, x='in_degree', hue='class', \n",
    "             kde=True, bins=30, palette=['#4285F4', '#EA4335'], ax=axes[0])\n",
    "axes[0].set_title('In-Degree Distribution by Class', fontsize=14)\n",
    "axes[0].set_xlabel('In-Degree', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].legend(title='Class', labels=['Legitimate', 'Fraudulent'])\n",
    "\n",
    "# Out-degree distribution\n",
    "sns.histplot(data=df_degrees, x='out_degree', hue='class', \n",
    "             kde=True, bins=30, palette=['#4285F4', '#EA4335'], ax=axes[1])\n",
    "axes[1].set_title('Out-Degree Distribution by Class', fontsize=14)\n",
    "axes[1].set_xlabel('Out-Degree', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].legend(title='Class', labels=['Legitimate', 'Fraudulent'])\n",
    "\n",
    "# Total degree distribution\n",
    "sns.histplot(data=df_degrees, x='total_degree', hue='class', \n",
    "             kde=True, bins=30, palette=['#4285F4', '#EA4335'], ax=axes[2])\n",
    "axes[2].set_title('Total Degree Distribution by Class', fontsize=14)\n",
    "axes[2].set_xlabel('Total Degree', fontsize=12)\n",
    "axes[2].set_ylabel('Count', fontsize=12)\n",
    "axes[2].legend(title='Class', labels=['Legitimate', 'Fraudulent'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the strongly connected components\n",
    "strongly_connected = list(nx.strongly_connected_components(G))\n",
    "weakly_connected = list(nx.weakly_connected_components(G))\n",
    "\n",
    "print(f\"Number of strongly connected components: {len(strongly_connected)}\")\n",
    "print(f\"Number of weakly connected components: {len(weakly_connected)}\")\n",
    "\n",
    "# Size of largest components\n",
    "sizes_strongly = [len(c) for c in strongly_connected]\n",
    "sizes_weakly = [len(c) for c in weakly_connected]\n",
    "\n",
    "print(f\"Size of largest strongly connected component: {max(sizes_strongly)}\")\n",
    "print(f\"Size of largest weakly connected component: {max(sizes_weakly)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize component size distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Filter out tiny components for better visualization\n",
    "min_size = 5\n",
    "filtered_sizes = [s for s in sizes_strongly if s >= min_size]\n",
    "\n",
    "plt.hist(filtered_sizes, bins=30, alpha=0.7, color='purple')\n",
    "plt.title(f'Size Distribution of Strongly Connected Components (size >= {min_size})', fontsize=15)\n",
    "plt.xlabel('Component Size', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a small subgraph for illustration\n",
    "# Choose the largest connected component that's not too large\n",
    "for component in sorted(strongly_connected, key=len, reverse=True):\n",
    "    if 50 <= len(component) <= 100:\n",
    "        sample_component = component\n",
    "        break\n",
    "else:\n",
    "    # If no suitable component found, take a random subset of nodes\n",
    "    sample_nodes = list(G.nodes())[:100]\n",
    "    sample_component = sample_nodes\n",
    "\n",
    "sample_subgraph = G.subgraph(sample_component)\n",
    "\n",
    "# Color nodes by class\n",
    "node_colors = []\n",
    "for node in sample_subgraph.nodes():\n",
    "    if node in node_id_to_class:\n",
    "        if node_id_to_class[node] == 1:\n",
    "            node_colors.append('#EA4335')  # Red for fraudulent\n",
    "        else:\n",
    "            node_colors.append('#4285F4')  # Blue for legitimate\n",
    "    else:\n",
    "        node_colors.append('gray')  # Gray for unknown\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "pos = nx.spring_layout(sample_subgraph, seed=42)  # Position nodes using force-directed layout\n",
    "\n",
    "nx.draw_networkx_nodes(sample_subgraph, pos, node_color=node_colors, node_size=100, alpha=0.8)\n",
    "nx.draw_networkx_edges(sample_subgraph, pos, alpha=0.2, arrowsize=10)\n",
    "\n",
    "plt.title('Sample Transaction Subgraph', fontsize=16)\n",
    "plt.axis('off')\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#4285F4', markersize=10, label='Legitimate'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#EA4335', markersize=10, label='Fraudulent'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='gray', markersize=10, label='Unknown')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyze Fraud Network Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify fraud nodes\n",
    "fraud_nodes = df_nodes[df_nodes['class'] == 1]['txId'].tolist()\n",
    "legitimate_nodes = df_nodes[df_nodes['class'] == 0]['txId'].tolist()\n",
    "\n",
    "# Calculate fraud connections\n",
    "fraud_to_fraud = 0\n",
    "fraud_to_legitimate = 0\n",
    "legitimate_to_fraud = 0\n",
    "legitimate_to_legitimate = 0\n",
    "\n",
    "for _, row in df_edges.iterrows():\n",
    "    source, target = row[0], row[1]\n",
    "    \n",
    "    if source in fraud_nodes and target in fraud_nodes:\n",
    "        fraud_to_fraud += 1\n",
    "    elif source in fraud_nodes and target in legitimate_nodes:\n",
    "        fraud_to_legitimate += 1\n",
    "    elif source in legitimate_nodes and target in fraud_nodes:\n",
    "        legitimate_to_fraud += 1\n",
    "    elif source in legitimate_nodes and target in legitimate_nodes:\n",
    "        legitimate_to_legitimate += 1\n",
    "\n",
    "print(\"Transaction flow patterns:\")\n",
    "print(f\"Fraud → Fraud: {fraud_to_fraud}\")\n",
    "print(f\"Fraud → Legitimate: {fraud_to_legitimate}\")\n",
    "print(f\"Legitimate → Fraud: {legitimate_to_fraud}\")\n",
    "print(f\"Legitimate → Legitimate: {legitimate_to_legitimate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize transaction flow patterns\n",
    "flow_labels = ['Fraud → Fraud', 'Fraud → Legitimate', 'Legitimate → Fraud', 'Legitimate → Legitimate']\n",
    "flow_values = [fraud_to_fraud, fraud_to_legitimate, legitimate_to_fraud, legitimate_to_legitimate]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(flow_labels, flow_values, color=['#EA4335', '#F4B400', '#F4B400', '#4285F4'])\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "             f'{height:,}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title('Transaction Flow Patterns', fontsize=15)\n",
    "plt.ylabel('Number of Transactions', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a log scale plot for better visualization of all categories\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(flow_labels, flow_values, color=['#EA4335', '#F4B400', '#F4B400', '#4285F4'], log=True)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height * 1.1,\n",
    "             f'{height:,}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title('Transaction Flow Patterns (Log Scale)', fontsize=15)\n",
    "plt.ylabel('Number of Transactions (Log Scale)', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary of Findings\n",
    "\n",
    "From our exploration of the Elliptic dataset, we can draw the following conclusions:\n",
    "\n",
    "1. **Data Overview**: The dataset contains [X] transactions (nodes) and [Y] transaction flows (edges).\n",
    "\n",
    "2. **Class Distribution**: Around [Z]% of transactions are labeled as fraudulent, making this an imbalanced classification problem.\n",
    "\n",
    "3. **Feature Analysis**:\n",
    "   - [X] features have very low variance and might be removed.\n",
    "   - Several features show strong correlation with the fraud label.\n",
    "   - PCA visualization shows some separation between legitimate and fraudulent transactions.\n",
    "\n",
    "4. **Graph Structure**:\n",
    "   - The transaction network is directed and [weakly/strongly] connected.\n",
    "   - It consists of multiple connected components.\n",
    "   - Fraudulent transactions tend to have [higher/lower] degrees compared to legitimate ones.\n",
    "\n",
    "5. **Fraud Patterns**:\n",
    "   - Most transaction flows occur between legitimate nodes.\n",
    "   - A significant number of legitimate-to-fraud and fraud-to-legitimate transactions exist.\n",
    "   - Fraud-to-fraud transactions are relatively rare.\n",
    "\n",
    "These insights will inform our feature engineering and model development approaches in the next notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
